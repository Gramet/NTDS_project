{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter users gender classification\n",
    "\n",
    "Schloesing Benjamin, Yao Yuan, Ramet Gaétan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The objective of this project is to find features which can help to determine a Twitter user's gender using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import data\n",
    "\n",
    "The dataset we will use is the [Twitter User Gender Classification](https://www.kaggle.com/crowdflower/twitter-user-gender-classification) dataset made available by [Crowdflower](https://www.crowdflower.com/). This datasets contains 20000 entries, each of them being a tweet from different users, with many other associated features which are listed here:\n",
    "\n",
    "* **_unit_id** : a unique id for each user\n",
    "* **_golden** : a boolean which states whether the user is included in the golden standard for the model\n",
    "* **_unit_state** : the state of the obervation, eiter *golden* for gold standards or *finalized* for contributor-judged\n",
    "* **_trusted_judgments** : the number of judgment on a user's gender. 3 for non-golden, or a unique id for golden\n",
    "* **_last_judgment_at** : date and time of the last judgment, blank for golden observations\n",
    "* **gender** : either *male*, *female* or *brand* for non-human profiles\n",
    "* **gender:confidence** : a float representing the confidence of the gender judgment\n",
    "* **profile_yn** : either *yes* or *no*, *no* meaning that the user's profile was not available when contributors went to judge it\n",
    "* **profile_yn:confidence** : confidence in the existence/non-existence of the profile\n",
    "* **created** : date and time of when the profile was created\n",
    "* **description** : the user's Tweeter profile description\n",
    "* **fav_number** : the amount of favorited tweets by the user\n",
    "* **gender_gold** : the gender if the profile is golden\n",
    "* **link_color** : the link color of the profile as a hex value\n",
    "* **name** : the Tweeter user's name\n",
    "* **profile_yn_gold** : *yes* or *no* whether the profile y/n value is golden\n",
    "* **profileimage** : a link to the profile image\n",
    "* **retweet_count** : the number of times the user has retweeted something\n",
    "* **sidebar_color** : color of the profile sidebar as a hex value\n",
    "* **text** : text of a random tweet from the user\n",
    "* **tweet_coord** : if the location was available at the time of the tweet, the coordinates as a string ith the format[latitude, longitude]\n",
    "* **tweet_count** : number of tweet of the users\n",
    "* **tweet_created** : the time of the random tweet in **text**\n",
    "* **tweet_id** : the tweet id of the random tweet\n",
    "* **tweet_location** : the location of the tweet, based on the coordinates\n",
    "* **user_timezone** : the timezone of the user\n",
    "\n",
    "Most of these features are not relevant for our analysis, we will only focus on a few of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we need latin-1 encoding because there are some special characters (é,...) that do not fit in default UTF-8\n",
    "dataFrame = pd.read_csv('gender-classifier-DFE-791531.csv', encoding='latin-1')\n",
    "\n",
    "#Show a sample of the dataset\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFrame.loc[:1,['name']]\n",
    "# Normalize text in the descriptions and tweet messages\n",
    "import re\n",
    "\n",
    "def text_normalizer(s):\n",
    "    #we will normalize the text by using strings, lowercases and removing all the punctuations\n",
    "    s = str(s) \n",
    "    s = s.lower()\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    #s = re.sub('\\s[^[@\\w]]',' ',s)\n",
    "    #s = re.sub('@',' atatatatat ',s)\n",
    "    s = re.sub('\\s+',' ',s) #replace double spaces with single spaces\n",
    "    \n",
    "    return s\n",
    "dataFrame['text_norm'] = [text_normalizer(s) for s in dataFrame['text']]\n",
    "dataFrame['description_norm'] = [text_normalizer(s) for s in dataFrame['description']]\n",
    "\n",
    "# Extract separate genders dataframes\n",
    "male_data = dataFrame[(dataFrame['gender']=='male')&(dataFrame['gender:confidence']==1)]\n",
    "female_data = dataFrame[(dataFrame['gender']=='female')&(dataFrame['gender:confidence']==1)]\n",
    "brand_data = dataFrame[(dataFrame['gender']=='brand')&(dataFrame['gender:confidence']==1)]\n",
    "male_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Exploration of which words are most used by which gender\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display\n",
    "\n",
    "def compute_bag_of_words(text):\n",
    "    vectorizer = CountVectorizer(encoding = 'latin-1',analyzer='word')\n",
    "    vectors = vectorizer.fit_transform(text)\n",
    "    vocabulary = vectorizer.get_feature_names()\n",
    "    return vectors, vocabulary\n",
    "\n",
    "def print_most_frequent(bow, vocab, n=20):\n",
    "    idx = np.argsort(bow.sum(axis=0))\n",
    "    for i in range(1,n+1):\n",
    "        j = idx[0, -i]\n",
    "        print(vocab[j])\n",
    "\n",
    "male_bow, male_voc = compute_bag_of_words(male_data['text_norm'])\n",
    "# temp = male_voc.index('thatjeanagirl_')\n",
    "# temp2 = male_bow.sum(axis=0)\n",
    "# print((male_bow.sum(axis=0)).shape)\n",
    "# print(temp)\n",
    "# print((male_bow.sum(axis=0))[0,temp])\n",
    "# print(male_voc)\n",
    "print_most_frequent(male_bow, male_voc)\n",
    "#nothing special about these words really\n",
    "print('---')\n",
    "female_bow, female_voc = compute_bag_of_words(female_data['text_norm'])\n",
    "\n",
    "print_most_frequent(female_bow, female_voc)\n",
    "#nothing special about these words really\n",
    "print('---')\n",
    "\n",
    "brand_bow, brand_voc = compute_bag_of_words(brand_data['text_norm'])\n",
    "\n",
    "print_most_frequent(brand_bow, brand_voc)\n",
    "#nothing special about these words really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Looking at the most used words per gender doesnt yield anything particular since we all use the same common words,\n",
    "#so let's try to find predictors\n",
    "\n",
    "#first let's put all the interesting text in one string for each tweet\n",
    "dataFrame['all_text'] =dataFrame['text_norm'].str.cat(dataFrame['description_norm'],sep=' ')\n",
    "dataFrameConf = dataFrame[(dataFrame['gender:confidence']==1)&(dataFrame['gender']!='unknown')]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "full_bow, full_voc = compute_bag_of_words(dataFrameConf['all_text'])\n",
    "X = full_bow\n",
    "y = LabelEncoder().fit_transform(dataFrameConf['gender'])\n",
    "# Encoder : 2 = male, 1 = female, 0 = brand\n",
    "\n",
    "# Create Training and testing sets.\n",
    "n,d = X.shape\n",
    "test_size = n // 5\n",
    "print('Split: {} testing and {} training samples'.format(test_size, y.size - test_size))\n",
    "perm = np.random.permutation(y.size)\n",
    "X_test  = X[perm[:test_size]]\n",
    "X_train = X[perm[test_size:]]\n",
    "y_test  = y[perm[:test_size]]\n",
    "y_train = y[perm[test_size:]]\n",
    "\n",
    "# Linear model regression\n",
    "from sklearn import linear_model, metrics\n",
    "\n",
    "%matplotlib notebook \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy import ndimage\n",
    "\n",
    "def model_test(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = metrics.mean_squared_error(y_test,y_pred)\n",
    "    print('mse: {:.4f}'.format(mse))\n",
    "\n",
    "    W = model.coef_\n",
    "    print('score: ', model.score(X_test,y_test))\n",
    "# Male Predictors \n",
    "    print('Best 20 male predictors:')\n",
    "    idx_male = np.argsort((W[2,:]))\n",
    "    weight_male_pred = np.zeros(20)\n",
    "    male_pred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_male[-1-i]\n",
    "        weight_male_pred[i] = W[2,j]\n",
    "        male_pred_label[i] = full_voc[j]\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_male_pred, bar_width, label = 'Male Predictors', color = '#0084b4')\n",
    "    plt.yticks(pred_number,male_pred_label)\n",
    "    plt.xlabel('Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 male predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Male Anti-Predictors    \n",
    "    print('Best 20 male anti-predictors:')\n",
    "    idx_male = np.argsort(-(W[2,:]))\n",
    "    weight_male_antipred = np.zeros(20)\n",
    "    male_antipred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_male[-1-i]\n",
    "        weight_male_antipred[i] = W[2,j]\n",
    "        male_antipred_label[i] = full_voc[j]\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_male_antipred, bar_width, label = 'Male Anti-Predictors', color = '#0084b4')\n",
    "    plt.yticks(pred_number,male_antipred_label)\n",
    "    plt.xlabel('Anti-Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 male anti-predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Female Predictors    \n",
    "    print('Best 20 female predictors:')\n",
    "    idx_female = np.argsort((W[1,:]))\n",
    "    weight_female_pred = np.zeros(20)\n",
    "    female_pred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_female[-1-i]\n",
    "        weight_female_pred[i] = W[1,j]\n",
    "        female_pred_label[i] = full_voc[j]\n",
    "\n",
    "    fig3, ax3 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_female_pred, bar_width, label = 'Female Predictors', color = '#f5abb5')\n",
    "    plt.yticks(pred_number,female_pred_label)\n",
    "    plt.xlabel('Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 female predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Female Anti-Predictors    \n",
    "    print('Best 20 female anti-predictors:')\n",
    "    idx_female = np.argsort(-(W[1,:]))\n",
    "    weight_female_antipred = np.zeros(20)\n",
    "    female_antipred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_female[-1-i]\n",
    "        weight_female_antipred[i] = W[1,j]\n",
    "        female_antipred_label[i] = full_voc[j]\n",
    "\n",
    "    fig4, ax4 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_female_antipred, bar_width, label = 'Female Anti-Predictors', color = '#f5abb5')\n",
    "    plt.yticks(pred_number,female_antipred_label)\n",
    "    plt.xlabel('Anti-Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 female anti-predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Brand Predictors    \n",
    "    print('Best 20 brand predictors:')\n",
    "    idx_brand = np.argsort((W[0,:]))\n",
    "    weight_brand_pred = np.zeros(20)\n",
    "    brand_pred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_brand[-1-i]\n",
    "        weight_brand_pred[i] = W[0,j]\n",
    "        brand_pred_label[i] = full_voc[j]\n",
    "\n",
    "    fig5, ax5 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_brand_pred, bar_width, label = 'Brand Predictors', color = '#4a913c')\n",
    "    plt.yticks(pred_number,brand_pred_label)\n",
    "    plt.xlabel('Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 brand predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Brand Anti-Predictors    \n",
    "    print('Best 20 brand anti-predictors:')\n",
    "    idx_brand = np.argsort(-(W[0,:]))\n",
    "    weight_brand_antipred = np.zeros(20)\n",
    "    brand_antipred_label = [\"\" for x in range(20)]\n",
    "    for i in range(20):\n",
    "        j = idx_brand[-1-i]\n",
    "        weight_brand_antipred[i] = W[0,j]\n",
    "        brand_antipred_label[i] = full_voc[j]\n",
    "\n",
    "    fig6, ax6 = plt.subplots()\n",
    "\n",
    "    bar_width = 0.5\n",
    "    pred_number = np.arange(20)+1\n",
    "    rects1 = plt.barh(pred_number,weight_brand_antipred, bar_width, label = 'Brand Anti-Predictors', color = '#4a913c')\n",
    "    plt.yticks(pred_number,brand_antipred_label)\n",
    "    plt.xlabel('Anti-Predictor')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.title('Best 20 brand anti-predictors')\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "model = linear_model.RidgeClassifier()\n",
    "print('Testing Ridge Classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.PassiveAggressiveClassifier()\n",
    "print('Testing Passive Aggressive classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.SGDClassifier()\n",
    "print('Testing SGD classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "print('Testing Logistic Regression model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
