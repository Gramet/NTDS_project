{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter users gender classification\n",
    "\n",
    "Schloesing Benjamin, Yao Yuan, Ramet Gaétan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The objective of this project is to find features which can help to determine a Twitter user's gender using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import data\n",
    "\n",
    "The dataset we will use is the [Twitter User Gender Classification](https://www.kaggle.com/crowdflower/twitter-user-gender-classification) dataset made available by [Crowdflower](https://www.crowdflower.com/). This datasets contains 20000 entries, each of them being a tweet from different users, with many other associated features which are listed here:\n",
    "\n",
    "* **_unit_id** : a unique id for each user\n",
    "* **_golden** : a boolean which states whether the user is included in the golden standard for the model\n",
    "* **_unit_state** : the state of the obervation, eiter *golden* for gold standards or *finalized* for contributor-judged\n",
    "* **_trusted_judgments** : the number of judgment on a user's gender. 3 for non-golden, or a unique id for golden\n",
    "* **_last_judgment_at** : date and time of the last judgment, blank for golden observations\n",
    "* **gender** : either *male*, *female* or *brand* for non-human profiles\n",
    "* **gender:confidence** : a float representing the confidence of the gender judgment\n",
    "* **profile_yn** : either *yes* or *no*, *no* meaning that the user's profile was not available when contributors went to judge it\n",
    "* **profile_yn:confidence** : confidence in the existence/non-existence of the profile\n",
    "* **created** : date and time of when the profile was created\n",
    "* **description** : the user's Tweeter profile description\n",
    "* **fav_number** : the amount of favorited tweets by the user\n",
    "* **gender_gold** : the gender if the profile is golden\n",
    "* **link_color** : the link color of the profile as a hex value\n",
    "* **name** : the Tweeter user's name\n",
    "* **profile_yn_gold** : *yes* or *no* whether the profile y/n value is golden\n",
    "* **profileimage** : a link to the profile image\n",
    "* **retweet_count** : the number of times the user has retweeted something\n",
    "* **sidebar_color** : color of the profile sidebar as a hex value\n",
    "* **text** : text of a random tweet from the user\n",
    "* **tweet_coord** : if the location was available at the time of the tweet, the coordinates as a string ith the format[latitude, longitude]\n",
    "* **tweet_count** : number of tweet of the users\n",
    "* **tweet_created** : the time of the random tweet in **text**\n",
    "* **tweet_id** : the tweet id of the random tweet\n",
    "* **tweet_location** : the location of the tweet, based on the coordinates\n",
    "* **user_timezone** : the timezone of the user\n",
    "\n",
    "Most of these features are not relevant for our analysis, we will only focus on a few of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226   False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227   False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228   False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229   False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230   False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created             ...              \\\n",
       "0    12/5/13 1:48             ...               \n",
       "1   10/1/12 13:51             ...               \n",
       "2  11/28/14 11:30             ...               \n",
       "3   6/11/09 22:39             ...               \n",
       "4   4/16/14 13:23             ...               \n",
       "\n",
       "                                        profileimage  retweet_count  \\\n",
       "0  https://pbs.twimg.com/profile_images/414342229...              0   \n",
       "1  https://pbs.twimg.com/profile_images/539604221...              0   \n",
       "2  https://pbs.twimg.com/profile_images/657330418...              1   \n",
       "3  https://pbs.twimg.com/profile_images/259703936...              0   \n",
       "4  https://pbs.twimg.com/profile_images/564094871...              0   \n",
       "\n",
       "  sidebar_color                                               text  \\\n",
       "0        FFFFFF  Robbie E Responds To Critics After Win Against...   \n",
       "1        C0DEED  ÛÏIt felt like they were my friends and I was...   \n",
       "2        C0DEED  i absolutely adore when louis starts the songs...   \n",
       "3        C0DEED  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "4             0  Watching Neighbours on Sky+ catching up with t...   \n",
       "\n",
       "  tweet_coord tweet_count   tweet_created      tweet_id   tweet_location  \\\n",
       "0         NaN      110964  10/26/15 12:40  6.587300e+17  main; @Kan1shk3   \n",
       "1         NaN        7471  10/26/15 12:40  6.587300e+17              NaN   \n",
       "2         NaN        5617  10/26/15 12:40  6.587300e+17           clcncl   \n",
       "3         NaN        1693  10/26/15 12:40  6.587300e+17    Palo Alto, CA   \n",
       "4         NaN       31462  10/26/15 12:40  6.587300e+17              NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                     Chennai  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2                    Belgrade  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we need latin-1 encoding because there are some special characters (é,...) that do not fit in default UTF-8\n",
    "dataFrame = pd.read_csv('gender-classifier-DFE-791531.csv', encoding='latin-1')\n",
    "\n",
    "#Show a sample of the dataset\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>description_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>robbie e responds to critics after win against...</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>ûïit felt like they were my friends and i was...</td>\n",
       "      <td>i'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>hi jordanspieth looking at the url do you use ...</td>\n",
       "      <td>mobile guy 49ers shazam google kleiner perkins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>815719233</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:48</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/3/12 21:54</td>\n",
       "      <td>...</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Gala Bingo clubs bought for å£241m: The UK's l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112117</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gala bingo clubs bought for å£241m the uk's la...</td>\n",
       "      <td>the secret of getting ahead is getting started.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>815719243</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 22:50</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/18/09 11:41</td>\n",
       "      <td>...</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>@coolyazzy94 Ditto - I'm still learning the fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>London</td>\n",
       "      <td>@coolyazzy94 ditto i'm still learning the favo...</td>\n",
       "      <td>over enthusiastic f1 fan model collector music...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0   815719226   False   finalized                   3    10/26/15 23:24   \n",
       "1   815719227   False   finalized                   3    10/26/15 23:30   \n",
       "3   815719229   False   finalized                   3    10/26/15 23:10   \n",
       "7   815719233   False   finalized                   3    10/26/15 23:48   \n",
       "17  815719243   False   finalized                   3    10/26/15 22:50   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male                1.0        yes                    1.0   \n",
       "1    male                1.0        yes                    1.0   \n",
       "3    male                1.0        yes                    1.0   \n",
       "7    male                1.0        yes                    1.0   \n",
       "17   male                1.0        yes                    1.0   \n",
       "\n",
       "           created                        ...                          \\\n",
       "0     12/5/13 1:48                        ...                           \n",
       "1    10/1/12 13:51                        ...                           \n",
       "3    6/11/09 22:39                        ...                           \n",
       "7    12/3/12 21:54                        ...                           \n",
       "17  10/18/09 11:41                        ...                           \n",
       "\n",
       "   sidebar_color                                               text  \\\n",
       "0         FFFFFF  Robbie E Responds To Critics After Win Against...   \n",
       "1         C0DEED  ÛÏIt felt like they were my friends and I was...   \n",
       "3         C0DEED  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "7         C0DEED  Gala Bingo clubs bought for å£241m: The UK's l...   \n",
       "17        C0DEED  @coolyazzy94 Ditto - I'm still learning the fa...   \n",
       "\n",
       "   tweet_coord tweet_count   tweet_created      tweet_id   tweet_location  \\\n",
       "0          NaN      110964  10/26/15 12:40  6.587300e+17  main; @Kan1shk3   \n",
       "1          NaN        7471  10/26/15 12:40  6.587300e+17              NaN   \n",
       "3          NaN        1693  10/26/15 12:40  6.587300e+17    Palo Alto, CA   \n",
       "7          NaN      112117  10/26/15 12:40  6.587300e+17              NaN   \n",
       "17         NaN          91  10/26/15 12:40  6.587300e+17          Glasgow   \n",
       "\n",
       "                 user_timezone  \\\n",
       "0                      Chennai   \n",
       "1   Eastern Time (US & Canada)   \n",
       "3   Pacific Time (US & Canada)   \n",
       "7                          NaN   \n",
       "17                      London   \n",
       "\n",
       "                                            text_norm  \\\n",
       "0   robbie e responds to critics after win against...   \n",
       "1   ûïit felt like they were my friends and i was...   \n",
       "3   hi jordanspieth looking at the url do you use ...   \n",
       "7   gala bingo clubs bought for å£241m the uk's la...   \n",
       "17  @coolyazzy94 ditto i'm still learning the favo...   \n",
       "\n",
       "                                     description_norm  \n",
       "0                               i sing my own rhythm.  \n",
       "1   i'm the author of novels filled with family dr...  \n",
       "3   mobile guy 49ers shazam google kleiner perkins...  \n",
       "7     the secret of getting ahead is getting started.  \n",
       "17  over enthusiastic f1 fan model collector music...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.loc[:1,['name']]\n",
    "# Normalize text in the descriptions and tweet messages\n",
    "import re\n",
    "\n",
    "def text_normalizer(s):\n",
    "    #we will normalize the text by using strings, lowercases and removing all the punctuations\n",
    "    s = str(s) \n",
    "    s = s.lower()\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\s+',' ',s) #replace double spaces with single spaces\n",
    "    \n",
    "    return s\n",
    "dataFrame['text_norm'] = [text_normalizer(s) for s in dataFrame['text']]\n",
    "dataFrame['description_norm'] = [text_normalizer(s) for s in dataFrame['description']]\n",
    "\n",
    "# Extract separate genders dataframes\n",
    "male_data = dataFrame[(dataFrame['gender']=='male')&(dataFrame['gender:confidence']==1)]\n",
    "female_data = dataFrame[(dataFrame['gender']=='female')&(dataFrame['gender:confidence']==1)]\n",
    "brand_data = dataFrame[(dataFrame['gender']=='brand')&(dataFrame['gender:confidence']==1)]\n",
    "male_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "the\n",
      "of\n",
      "to\n",
      "my\n",
      "in\n",
      "for\n",
      "nan\n",
      "you\n",
      "co\n",
      "is\n",
      "êû\n",
      "on\n",
      "me\n",
      "at\n",
      "it\n",
      "love\n",
      "http\n",
      "life\n",
      "all\n",
      "---\n",
      "and\n",
      "the\n",
      "of\n",
      "nan\n",
      "to\n",
      "my\n",
      "you\n",
      "in\n",
      "is\n",
      "me\n",
      "for\n",
      "love\n",
      "with\n",
      "it\n",
      "life\n",
      "on\n",
      "co\n",
      "be\n",
      "are\n",
      "all\n",
      "---\n",
      "the\n",
      "and\n",
      "for\n",
      "to\n",
      "of\n",
      "nan\n",
      "in\n",
      "co\n",
      "news\n",
      "http\n",
      "is\n",
      "on\n",
      "we\n",
      "from\n",
      "your\n",
      "you\n",
      "all\n",
      "with\n",
      "our\n",
      "at\n"
     ]
    }
   ],
   "source": [
    "#Exploration of which words are most used by which gender\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display\n",
    "\n",
    "def compute_bag_of_words(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectors = vectorizer.fit_transform(text)\n",
    "    vocabulary = vectorizer.get_feature_names()\n",
    "    return vectors, vocabulary\n",
    "\n",
    "def print_most_frequent(bow, vocab, n=20):\n",
    "    idx = np.argsort(bow.sum(axis=0))\n",
    "    for i in range(1,n+1):\n",
    "        j = idx[0, -i]\n",
    "        print(vocab[j])\n",
    "\n",
    "male_bow, male_voc = compute_bag_of_words(male_data['description_norm'])\n",
    "\n",
    "print_most_frequent(male_bow, male_voc)\n",
    "#nothing special about these words really\n",
    "print('---')\n",
    "female_bow, female_voc = compute_bag_of_words(female_data['description_norm'])\n",
    "\n",
    "print_most_frequent(female_bow, female_voc)\n",
    "#nothing special about these words really\n",
    "print('---')\n",
    "\n",
    "brand_bow, brand_voc = compute_bag_of_words(brand_data['description_norm'])\n",
    "\n",
    "print_most_frequent(brand_bow, brand_voc)\n",
    "#nothing special about these words really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 2760 testing and 11044 training samples\n",
      "Testing naive bayes multinomial model:\n",
      "mse: 0.4808\n",
      "score:  0.678985507246\n",
      "Best 20 male predictors and anti-predictors:\n",
      "weight:  0.49, word: father\n",
      "weight:  0.36, word: director\n",
      "weight:  0.35, word: man\n",
      "weight:  0.35, word: guy\n",
      "weight:  0.34, word: photographer\n",
      "weight: -0.33, word: mom\n",
      "weight:  0.33, word: dad\n",
      "weight:  0.33, word: journalist\n",
      "weight:  0.32, word: producer\n",
      "weight:  0.31, word: niggas\n",
      "weight:  0.30, word: engineer\n",
      "weight: -0.30, word: girl\n",
      "weight:  0.29, word: husband\n",
      "weight: -0.26, word: feminist\n",
      "weight:  0.25, word: ceo\n",
      "weight:  0.25, word: fan\n",
      "weight:  0.25, word: political\n",
      "weight:  0.25, word: season\n",
      "weight: -0.24, word: mum\n",
      "weight:  0.24, word: actor\n",
      "Best 20 female predictors and anti-predictors:\n",
      "weight:  0.42, word: mom\n",
      "weight:  0.41, word: girl\n",
      "weight:  0.38, word: mother\n",
      "weight:  0.35, word: lover\n",
      "weight:  0.34, word: mum\n",
      "weight:  0.34, word: 17\n",
      "weight: -0.33, word: father\n",
      "weight:  0.32, word: feminist\n",
      "weight:  0.30, word: blogger\n",
      "weight:  0.29, word: bed\n",
      "weight: -0.29, word: man\n",
      "weight:  0.28, word: ªá\n",
      "weight: -0.27, word: guy\n",
      "weight: -0.27, word: niggas\n",
      "weight:  0.26, word: woman\n",
      "weight: -0.26, word: dad\n",
      "weight:  0.26, word: makeup\n",
      "weight:  0.25, word: 18\n",
      "weight: -0.25, word: season\n",
      "weight:  0.25, word: girls\n",
      "Best 20 brand predictors and anti-predictors:\n",
      "weight:  0.39, word: official\n",
      "weight:  0.35, word: news\n",
      "weight:  0.35, word: channel\n",
      "weight:  0.34, word: weather\n",
      "weight: -0.26, word: consultant\n",
      "weight:  0.26, word: updates\n",
      "weight:  0.25, word: https\n",
      "weight: -0.25, word: photographer\n",
      "weight:  0.25, word: station\n",
      "weight: -0.24, word: writer\n",
      "weight: -0.24, word: author\n",
      "weight:  0.24, word: service\n",
      "weight:  0.23, word: us\n",
      "weight: -0.23, word: blogger\n",
      "weight: -0.22, word: ceo\n",
      "weight:  0.22, word: community\n",
      "weight: -0.21, word: lover\n",
      "weight: -0.21, word: founder\n",
      "weight: -0.21, word: owner\n",
      "weight:  0.20, word: information\n"
     ]
    }
   ],
   "source": [
    "#Looking at the most used words per gender doesnt yield anything particular since we all use the same common words,\n",
    "#so let's try to find predictors\n",
    "\n",
    "#first let's put all the interesting text in one string for each tweet\n",
    "dataFrame['all_text'] =dataFrame['text_norm'].str.cat(dataFrame['description_norm'],sep=' ')\n",
    "dataFrameConf = dataFrame[(dataFrame['gender:confidence']==1)&(dataFrame['gender']!='unknown')]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "full_bow, full_voc = compute_bag_of_words(dataFrameConf['all_text'])\n",
    "X = full_bow\n",
    "y = LabelEncoder().fit_transform(dataFrameConf['gender'])\n",
    "# Encoder : 2 = male, 1 = female, 0 = brand\n",
    "\n",
    "# Create Training and testing sets.\n",
    "n,d = X.shape\n",
    "test_size = n // 5\n",
    "print('Split: {} testing and {} training samples'.format(test_size, y.size - test_size))\n",
    "perm = np.random.permutation(y.size)\n",
    "X_test  = X[perm[:test_size]]\n",
    "X_train = X[perm[test_size:]]\n",
    "y_test  = y[perm[:test_size]]\n",
    "y_train = y[perm[test_size:]]\n",
    "\n",
    "# Linear model regression\n",
    "from sklearn import linear_model, metrics\n",
    "\n",
    "def model_test(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = metrics.mean_squared_error(y_test,y_pred)\n",
    "    print('mse: {:.4f}'.format(mse))\n",
    "\n",
    "    W = model.coef_\n",
    "    idx = np.argsort((W))\n",
    "    print('score: ', model.score(X_test,y_test))\n",
    "\n",
    "    print('Best 20 male predictors and anti-predictors:')\n",
    "    idx_male = np.argsort(abs(W[2,:]))\n",
    "    for i in range(20):\n",
    "        j = idx_male[-1-i]\n",
    "        print('weight: {:5.2f}, word: {}'.format(W[2,j], full_voc[j]))\n",
    "        \n",
    "    print('Best 20 female predictors and anti-predictors:')\n",
    "    idx_female = np.argsort(abs(W[1,:]))\n",
    "    for i in range(20):\n",
    "        j = idx_female[-1-i]\n",
    "        print('weight: {:5.2f}, word: {}'.format(W[1,j], full_voc[j]))\n",
    "        \n",
    "    print('Best 20 brand predictors and anti-predictors:')\n",
    "    idx_brand = np.argsort(abs(W[0,:]))\n",
    "    for i in range(20):\n",
    "        j = idx_brand[-1-i]\n",
    "        print('weight: {:5.2f}, word: {}'.format(W[0,j], full_voc[j]))\n",
    "\n",
    "model = linear_model.RidgeClassifier()\n",
    "print('Testing Ridge Classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Passive Aggressive classifier model:\n",
      "mse: 0.5181\n",
      "score:  0.665579710145\n",
      "Best 20 male predictors and anti-predictors:\n",
      "weight:  1.32, word: father\n",
      "weight:  0.93, word: engineer\n",
      "weight:  0.92, word: smoking\n",
      "weight:  0.91, word: a6geg73buc\n",
      "weight:  0.91, word: retire\n",
      "weight:  0.89, word: goat\n",
      "weight:  0.88, word: loyal\n",
      "weight:  0.87, word: king\n",
      "weight:  0.86, word: director\n",
      "weight:  0.85, word: dad\n",
      "weight:  0.84, word: niggas\n",
      "weight:  0.84, word: smoke\n",
      "weight:  0.82, word: steal\n",
      "weight:  0.81, word: bread\n",
      "weight: -0.81, word: feminist\n",
      "weight: -0.81, word: _ùªä\n",
      "weight:  0.80, word: marketer\n",
      "weight:  0.79, word: photographer\n",
      "weight:  0.79, word: mate\n",
      "weight:  0.77, word: nickiminaj\n",
      "Best 20 female predictors and anti-predictors:\n",
      "weight: -1.14, word: father\n",
      "weight: -0.98, word: loyal\n",
      "weight: -0.96, word: schaeavery\n",
      "weight: -0.96, word: smoke\n",
      "weight: -0.95, word: king\n",
      "weight: -0.95, word: bread\n",
      "weight: -0.94, word: mate\n",
      "weight:  0.90, word: adam\n",
      "weight:  0.90, word: mum\n",
      "weight:  0.88, word: mother\n",
      "weight: -0.85, word: retire\n",
      "weight: -0.84, word: marry\n",
      "weight: -0.83, word: official\n",
      "weight:  0.82, word: mommy\n",
      "weight:  0.81, word: literally\n",
      "weight:  0.81, word: entered\n",
      "weight: -0.81, word: nickiminaj\n",
      "weight:  0.81, word: _ùªä\n",
      "weight:  0.81, word: eyebrows\n",
      "weight:  0.80, word: makeup\n",
      "Best 20 brand predictors and anti-predictors:\n",
      "weight:  1.01, word: x8\n",
      "weight: -0.96, word: lover\n",
      "weight: -0.92, word: photographer\n",
      "weight: -0.92, word: consultant\n",
      "weight:  0.80, word: updates\n",
      "weight:  0.75, word: station\n",
      "weight:  0.74, word: pet\n",
      "weight:  0.72, word: subscribe\n",
      "weight:  0.69, word: official\n",
      "weight: -0.68, word: taking\n",
      "weight: -0.68, word: sc\n",
      "weight: -0.68, word: move\n",
      "weight: -0.67, word: writer\n",
      "weight: -0.66, word: ceo\n",
      "weight:  0.65, word: news\n",
      "weight: -0.64, word: strategist\n",
      "weight:  0.64, word: information\n",
      "weight: -0.64, word: singer\n",
      "weight:  0.63, word: cab\n",
      "weight:  0.63, word: nsfw\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.PassiveAggressiveClassifier()\n",
    "print('Testing Passive Aggressive classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear Regression model:\n",
      "mse: 0.5801\n",
      "score:  0.647101449275\n",
      "Best 20 male predictors and anti-predictors:\n",
      "weight: -5.69, word: kath\n",
      "weight:  4.27, word: father\n",
      "weight:  3.74, word: marketer\n",
      "weight:  3.20, word: niggas\n",
      "weight:  3.20, word: photographer\n",
      "weight:  3.20, word: engineer\n",
      "weight:  3.02, word: journalist\n",
      "weight: -3.02, word: beauty\n",
      "weight: -2.85, word: queen\n",
      "weight:  2.85, word: nickiminaj\n",
      "weight:  2.85, word: dad\n",
      "weight:  2.85, word: actor\n",
      "weight: -2.85, word: girl\n",
      "weight: -2.67, word: mum\n",
      "weight:  2.67, word: comedian\n",
      "weight:  2.67, word: producer\n",
      "weight:  2.67, word: director\n",
      "weight:  2.49, word: cars\n",
      "weight:  2.49, word: drummer\n",
      "weight:  2.49, word: pre\n",
      "Best 20 female predictors and anti-predictors:\n",
      "weight:  5.69, word: kath\n",
      "weight: -3.38, word: father\n",
      "weight: -3.20, word: êû\n",
      "weight:  3.20, word: mom\n",
      "weight:  3.02, word: mommy\n",
      "weight:  2.85, word: communication\n",
      "weight:  2.85, word: mum\n",
      "weight: -2.85, word: dad\n",
      "weight: -2.85, word: official\n",
      "weight:  2.67, word: difference\n",
      "weight: -2.67, word: niggas\n",
      "weight:  2.67, word: bed\n",
      "weight: -2.67, word: daddy\n",
      "weight:  2.67, word: µ_\n",
      "weight:  2.67, word: mother\n",
      "weight:  2.67, word: µû\n",
      "weight:  2.49, word: woman\n",
      "weight:  2.49, word: fangirl\n",
      "weight:  2.49, word: actress\n",
      "weight: -2.49, word: students\n",
      "Best 20 brand predictors and anti-predictors:\n",
      "weight: -5.34, word: é_\n",
      "weight: -3.38, word: consultant\n",
      "weight: -3.38, word: photographer\n",
      "weight: -3.20, word: ceo\n",
      "weight:  3.20, word: official\n",
      "weight: -3.02, word: lover\n",
      "weight:  3.02, word: updates\n",
      "weight:  3.02, word: station\n",
      "weight: -2.85, word: owner\n",
      "weight: -2.67, word: singer\n",
      "weight:  2.67, word: pet\n",
      "weight:  2.49, word: send\n",
      "weight:  2.49, word: https\n",
      "weight:  2.49, word: news\n",
      "weight:  2.31, word: â_\n",
      "weight:  2.31, word: cab\n",
      "weight:  2.31, word: information\n",
      "weight: -2.31, word: writer\n",
      "weight: -2.13, word: êû\n",
      "weight:  2.13, word: original\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.SGDClassifier()\n",
    "print('Testing SGD classifier model:')\n",
    "model_test(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
